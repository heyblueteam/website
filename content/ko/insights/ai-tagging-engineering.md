---
title: AI 자동 분류 (엔지니어링 심층 분석)
category: "Engineering"
description: Blue 엔지니어링 팀이 AI 기반 자동 분류 및 태깅 기능을 어떻게 구축했는지 무대 뒤 이야기를 들어보세요.
date: 2024-12-07
---

최근 저희는 모든 Blue 사용자에게 [AI 자동 분류](/insights/ai-auto-categorization) 기능을 출시했습니다. 이는 추가 비용 없이 Blue의 핵심 구독에 포함된 AI 기능입니다. 이 포스트에서는 이 기능을 구현하는 데 필요했던 엔지니어링에 대해 자세히 살펴보겠습니다.

---
Blue에서 저희의 기능 개발 접근 방식은 사용자 요구사항과 시장 동향에 대한 깊은 이해와 더불어 플랫폼을 정의하는 단순성과 사용 편의성을 유지하려는 노력에 뿌리를 두고 있습니다. 이것이 저희의 [로드맵](/platform/roadmap)을 이끄는 원동력이며, [수년간 매달 지속적으로 기능을 출시할 수 있게 한](/platform/changelog) 요인입니다.

Blue에 AI 기반 자동 태깅을 도입한 것은 이러한 철학이 실제로 구현된 완벽한 예입니다. 이 기능을 어떻게 구축했는지 기술적인 세부 사항을 살펴보기 전에, 저희가 해결하려고 했던 문제와 개발 과정에서의 신중한 고려사항을 이해하는 것이 중요합니다.

프로젝트 관리 환경은 빠르게 진화하고 있으며, AI 기능은 사용자 기대치의 중심이 되고 있습니다. 특히 수백만 개의 [레코드](/platform/features/records)를 가진 대규모 [프로젝트](/platform)를 관리하는 고객들은 데이터를 더 스마트하고 효율적으로 구성하고 분류하는 방법에 대한 요구를 적극적으로 표현해왔습니다.

그러나 Blue에서는 단순히 트렌디하거나 요청받았다는 이유로 기능을 추가하지 않습니다. 저희의 철학은 모든 새로운 추가 기능이 강력한 수요와 명확한 유용성을 입증할 때까지 기본 답변은 확고한 *"아니오"*라는 것입니다.

문제의 깊이와 AI 자동 태깅의 잠재력을 진정으로 이해하기 위해, 저희는 여러 도메인에 걸쳐 복잡하고 데이터가 풍부한 프로젝트를 관리하는 장기 사용자들을 중심으로 광범위한 고객 인터뷰를 수행했습니다.

이러한 대화를 통해 공통적인 맥락이 드러났습니다: *태깅은 구성과 검색 가능성에 매우 유용했지만, 수동 작업의 특성상 특히 대량의 레코드를 다루는 팀에게는 병목 현상이 되고 있었습니다.*

하지만 저희는 단순히 수동 태깅의 즉각적인 문제점을 해결하는 것 이상을 보았습니다.

저희는 AI 기반 태깅이 더 지능적이고 자동화된 워크플로우의 기반이 될 수 있는 미래를 구상했습니다.

이 기능의 진정한 힘은 [프로젝트 관리 자동화 시스템](/platform/features/automations)과의 잠재적 통합에 있다는 것을 깨달았습니다. 정보를 지능적으로 분류할 뿐만 아니라 그러한 카테고리를 사용하여 작업을 라우팅하고, 액션을 트리거하며, 실시간으로 워크플로우를 조정하는 프로젝트 관리 도구를 상상해보세요.

이 비전은 Blue를 단순하면서도 강력하게 유지하려는 저희의 목표와 완벽하게 일치했습니다.

더 나아가, 저희는 이 기능을 플랫폼의 한계를 넘어 확장할 수 있는 잠재력을 인식했습니다. 강력한 AI 태깅 시스템을 개발함으로써, 즉시 사용 가능한 "분류 API"의 기반을 마련하고 있었으며, 이는 사용자들이 더 넓은 기술 생태계에서 Blue와 상호작용하고 활용하는 새로운 방법을 열어줄 수 있습니다.

따라서 이 기능은 단순히 기능 목록에 AI 체크박스를 추가하는 것이 아니었습니다.

단순성과 사용자 중심성이라는 핵심 철학을 유지하면서 더 지능적이고 적응력 있는 프로젝트 관리 플랫폼을 향한 중요한 발걸음이었습니다.

다음 섹션에서는 이 비전을 실현하는 과정에서 직면한 기술적 과제, 이를 지원하기 위해 설계한 아키텍처, 그리고 구현한 솔루션에 대해 자세히 살펴보겠습니다. 또한 이 기능이 열어주는 미래의 가능성을 탐구하여, 신중하게 고려된 추가 기능이 프로젝트 관리의 혁신적인 변화를 위한 길을 어떻게 열 수 있는지 보여드리겠습니다.

---
## 문제

위에서 논의한 바와 같이, 프로젝트 레코드의 수동 태깅은 시간이 많이 걸리고 일관성이 없을 수 있습니다.

저희는 레코드 내용을 기반으로 태그를 자동으로 제안하기 위해 AI를 활용하여 이 문제를 해결하기로 했습니다.

주요 과제는 다음과 같았습니다:

1. 적절한 AI 모델 선택
2. 대량의 레코드를 효율적으로 처리
3. 데이터 프라이버시와 보안 보장
4. 기존 아키텍처에 기능을 원활하게 통합

## AI 모델 선택

저희는 [OpenAI](https://openai.com), [HuggingFace](https://huggingface.co/)의 오픈소스 모델, [Replicate](https://replicate.com) 등 여러 AI 플랫폼을 평가했습니다.

저희의 기준은 다음과 같았습니다:

- 비용 효율성
- 맥락 이해의 정확성
- 특정 출력 형식 준수 능력
- 데이터 프라이버시 보장

철저한 테스트 후, OpenAI의 [GPT-3.5 Turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)를 선택했습니다. [GPT-4](https://softgist.com/the-ultimate-guide-to-prompt-engineering)가 정확도 면에서 약간의 개선을 제공할 수 있지만, 저희의 테스트 결과 GPT-3.5의 성능이 자동 태깅 요구사항에 충분히 적합한 것으로 나타났습니다. 비용 효율성과 강력한 분류 기능의 균형이 이 기능을 위한 이상적인 선택이 되었습니다.

GPT-4의 높은 비용은 이 기능을 유료 추가 기능으로 제공해야 했을 것이며, 이는 **최종 사용자에게 추가 비용 없이 메인 제품 내에 AI를 번들로 제공**하려는 저희의 목표와 상충되었을 것입니다.

구현 당시 GPT-3.5 Turbo의 가격은 다음과 같습니다:

- 입력 토큰 1K당 $0.0005 (또는 입력 토큰 1M당 $0.50)
- 출력 토큰 1K당 $0.0015 (또는 출력 토큰 1M당 $1.50)

Blue의 평균 레코드에 대해 몇 가지 가정을 해보겠습니다:

- **제목**: ~10 토큰
- **설명**: ~50 토큰
- **댓글 2개**: 각각 ~30 토큰
- **사용자 정의 필드 5개**: 각각 ~10 토큰
- **목록 이름, 마감일 및 기타 메타데이터**: ~20 토큰
- **시스템 프롬프트 및 사용 가능한 태그**: ~50 토큰

레코드당 총 입력 토큰: 10 + 50 + (30 * 2) + (10 * 5) + 20 + 50 ≈ 240 토큰

출력의 경우, 레코드당 평균 3개의 태그가 제안된다고 가정하면, JSON 형식을 포함하여 총 약 20개의 출력 토큰이 될 수 있습니다.

100만 개의 레코드의 경우:

- 입력 비용: (240 * 1,000,000 / 1,000,000) * $0.50 = $120
- 출력 비용: (20 * 1,000,000 / 1,000,000) * $1.50 = $30

**100만 개 레코드를 자동 태깅하는 총 비용: $120 + $30 = $150**

## GPT3.5 Turbo 성능

분류는 GPT-3.5 Turbo와 같은 대규모 언어 모델(LLMs)이 특히 뛰어난 작업으로, 저희의 자동 태깅 기능에 특히 적합합니다. LLMs는 방대한 양의 텍스트 데이터로 학습되어 맥락, 의미론, 개념 간의 관계를 이해할 수 있습니다. 이러한 광범위한 지식 기반을 통해 다양한 도메인에서 높은 정확도로 분류 작업을 수행할 수 있습니다.

프로젝트 관리 태깅이라는 저희의 특정 사용 사례에서 GPT-3.5 Turbo는 몇 가지 주요 강점을 보여줍니다:

- **맥락 이해:** 개별 단어뿐만 아니라 전체 설명, 댓글 및 기타 필드에서 전달되는 의미를 고려하여 프로젝트 레코드의 전반적인 맥락을 파악할 수 있습니다.
- **유연성:** 광범위한 재프로그래밍 없이 다양한 프로젝트 유형과 산업에 적응할 수 있습니다.
- **모호성 처리:** 미묘한 결정을 내리기 위해 여러 요소를 고려할 수 있습니다.
- **예제로부터 학습:** 추가 학습 없이 새로운 분류 체계를 빠르게 이해하고 적용할 수 있습니다.
- **다중 레이블 분류:** 단일 레코드에 대해 여러 관련 태그를 제안할 수 있으며, 이는 저희 요구사항에 매우 중요했습니다.

GPT-3.5 Turbo는 또한 저희가 요구하는 JSON 출력 형식을 준수하는 데 있어서 신뢰성이 뛰어났으며, 이는 기존 시스템과의 원활한 통합에 *필수적*이었습니다. 오픈소스 모델들은 유망했지만, 종종 추가 주석을 추가하거나 예상 형식에서 벗어나 추가적인 후처리가 필요했을 것입니다. 이러한 출력 형식의 일관성은 저희의 결정에서 핵심 요소였으며, 구현을 크게 단순화하고 잠재적인 실패 지점을 줄였습니다.

일관된 JSON 출력을 제공하는 GPT-3.5 Turbo를 선택함으로써 더 간단하고 신뢰할 수 있으며 유지 관리가 용이한 솔루션을 구현할 수 있었습니다.

만약 덜 신뢰할 수 있는 형식의 모델을 선택했다면, 다양한 출력 형식을 처리하기 위한 강력한 파싱 로직의 필요성, 일관되지 않은 출력에 대한 광범위한 오류 처리, 추가 처리로 인한 잠재적인 성능 영향, 모든 출력 변형을 다루기 위한 테스트 복잡성 증가, 더 큰 장기적 유지 관리 부담 등 연쇄적인 복잡성에 직면했을 것입니다.

파싱 오류는 잘못된 태깅으로 이어져 사용자 경험에 부정적인 영향을 미칠 수 있습니다. 이러한 함정을 피함으로써 예측할 수 없는 AI 출력과 씨름하는 대신 성능 최적화 및 사용자 인터페이스 디자인과 같은 중요한 측면에 엔지니어링 노력을 집중할 수 있었습니다.

## 시스템 아키텍처

저희의 AI 자동 태깅 기능은 원활한 사용자 경험을 제공하면서 대량의 요청을 효율적으로 처리하도록 설계된 강력하고 확장 가능한 아키텍처를 기반으로 구축되었습니다. 모든 시스템과 마찬가지로, 현재 경험하는 것보다 한 단계 더 많은 트래픽을 지원하도록 이 기능을 설계했습니다. 이러한 접근 방식은 현재 요구사항에 비해 과도하게 설계된 것처럼 보일 수 있지만, 갑작스러운 사용량 급증을 원활하게 처리하고 주요 아키텍처 개편 없이 성장을 위한 충분한 여유를 제공하는 모범 사례입니다. 그렇지 않으면 18개월마다 모든 시스템을 재설계해야 할 것입니다 — 과거에 어렵게 배운 교훈입니다!

시스템의 구성 요소와 흐름을 살펴보겠습니다:

- **사용자 상호작용:** 프로세스는 사용자가 Blue 인터페이스에서 "자동 태그" 버튼을 누를 때 시작됩니다. 이 작업은 자동 태깅 워크플로우를 트리거합니다.
- **Blue API 호출:** 사용자의 작업은 Blue 백엔드에 대한 API 호출로 변환됩니다. 이 API 엔드포인트는 자동 태깅 요청을 처리하도록 설계되었습니다.
- **큐 관리:** 높은 부하에서 성능 문제를 일으킬 수 있는 즉시 처리 대신, 태깅 요청을 큐에 추가합니다. 이 큐잉 메커니즘에는 Redis를 사용하여 효과적으로 부하를 관리하고 시스템 확장성을 보장합니다.
- **백그라운드 서비스:** 새로운 요청에 대해 큐를 지속적으로 모니터링하는 백그라운드 서비스를 구현했습니다. 이 서비스는 큐에 있는 요청을 처리하는 역할을 담당합니다.
- **OpenAI API 통합:** 백그라운드 서비스는 필요한 데이터를 준비하고 OpenAI의 GPT-3.5 모델에 API 호출을 합니다. 여기서 실제 AI 기반 태깅이 발생합니다. 관련 프로젝트 데이터를 보내고 제안된 태그를 받습니다.
- **결과 처리:** 백그라운드 서비스는 OpenAI로부터 받은 결과를 처리합니다. 여기에는 AI의 응답을 파싱하고 프로젝트에 적용할 데이터를 준비하는 작업이 포함됩니다.
- **태그 적용:** 처리된 결과는 프로젝트의 관련 항목에 새 태그를 적용하는 데 사용됩니다. 이 단계에서 AI가 제안한 태그로 데이터베이스를 업데이트합니다.
- **사용자 인터페이스 반영:** 마지막으로 새 태그가 사용자의 프로젝트 보기에 나타나며, 사용자 관점에서 자동 태깅 프로세스가 완료됩니다.

이 아키텍처는 시스템 성능과 사용자 경험을 모두 향상시키는 몇 가지 주요 이점을 제공합니다. 큐와 백그라운드 처리를 활용함으로써 시스템에 과부하를 주거나 OpenAI API의 속도 제한에 도달하지 않고 많은 요청을 동시에 처리할 수 있는 인상적인 확장성을 달성했습니다. 이 아키텍처를 구현하려면 최적의 성능과 신뢰성을 보장하기 위해 다양한 요소를 신중하게 고려해야 했습니다. 큐 관리를 위해 Redis를 선택하여 분산 큐 처리의 속도와 신뢰성을 활용했습니다.

이 접근 방식은 또한 기능의 전반적인 응답성에 기여합니다. 실제 태깅에 시간이 걸리더라도 사용자는 요청이 처리되고 있다는 즉각적인 피드백을 받아 실시간 상호작용의 느낌을 만듭니다. 아키텍처의 내결함성은 또 다른 중요한 장점입니다. 일시적인 OpenAI API 중단과 같이 프로세스의 일부에서 문제가 발생하더라도 전체 시스템에 영향을 주지 않고 우아하게 재시도하거나 실패를 처리할 수 있습니다.

태그의 실시간 표시와 결합된 이러한 견고함은 사용자 경험을 향상시켜 AI "마법"이 작동하는 것처럼 느끼게 합니다.

## 데이터 및 프롬프트

자동 태깅 프로세스의 중요한 단계는 GPT-3.5 모델로 전송할 데이터를 준비하는 것입니다. 이 단계는 정확한 태깅을 위한 충분한 맥락을 제공하면서 효율성을 유지하고 사용자 프라이버시를 보호하는 균형을 맞추기 위해 신중한 고려가 필요했습니다. 다음은 저희의 데이터 준비 프로세스에 대한 자세한 내용입니다.

각 레코드에 대해 다음 정보를 수집합니다:

- **목록 이름**: 프로젝트의 더 넓은 카테고리나 단계에 대한 맥락을 제공합니다.
- **레코드 제목**: 종종 레코드의 목적이나 내용에 대한 주요 정보를 포함합니다.
- **사용자 정의 필드**: 텍스트 및 숫자 기반 [사용자 정의 필드](/platform/features/custom-fields)를 포함하며, 종종 중요한 프로젝트별 정보를 포함합니다.
- **설명**: 일반적으로 레코드에 대한 가장 자세한 정보를 포함합니다.
- **댓글**: 태깅과 관련될 수 있는 추가 맥락이나 업데이트를 제공할 수 있습니다.
- **마감일**: 태그 선택에 영향을 줄 수 있는 시간 정보입니다.

흥미롭게도, 저희는 기존 태그 데이터를 GPT-3.5에 전송하지 않으며, 이는 모델의 편향을 피하기 위함입니다.

자동 태깅 기능의 핵심은 GPT-3.5 모델과 상호작용하고 응답을 처리하는 방법에 있습니다. 파이프라인의 이 섹션은 정확하고 일관되며 효율적인 태깅을 보장하기 위해 신중한 설계가 필요했습니다.

저희는 AI에게 작업을 지시하기 위해 신중하게 제작된 시스템 프롬프트를 사용합니다. 다음은 프롬프트와 각 구성 요소의 근거에 대한 분석입니다:

```
You will be provided with record data, and your task is to choose the tags that are relevant to the record.
You can respond with an empty array if you are unsure.
Available tags: ${tags}.
Today: ${currentDate}.
Please respond in JSON using the following format:
{ "tags": ["tag-1", "tag-2"] }
```

- **작업 정의:** 집중된 응답을 보장하기 위해 AI의 작업을 명확하게 명시합니다.
- **불확실성 처리:** AI가 확실하지 않을 때 강제 태깅을 방지하기 위해 빈 응답을 명시적으로 허용합니다.
- **사용 가능한 태그:** AI의 선택을 기존 프로젝트 태그로 제한하기 위해 유효한 태그 목록(${tags})을 제공합니다.
- **현재 날짜:** ${currentDate}를 포함하면 AI가 시간적 맥락을 이해하는 데 도움이 되며, 이는 특정 유형의 프로젝트에 중요할 수 있습니다.
- **응답 형식:** 쉬운 파싱과 오류 확인을 위해 JSON 형식을 지정합니다.

이 프롬프트는 광범위한 테스트와 반복의 결과입니다. 작업, 사용 가능한 옵션 및 원하는 출력 형식에 대해 명시적으로 설명하면 AI 응답의 정확성과 일관성이 크게 향상된다는 것을 발견했습니다 — 단순함이 핵심입니다!

사용 가능한 태그 목록은 서버 측에서 생성되며 프롬프트에 포함되기 전에 검증됩니다. 대형 프롬프트를 방지하기 위해 태그 이름에 엄격한 문자 제한을 구현합니다.

위에서 언급했듯이, GPT-3.5 Turbo가 100% 올바른 형식의 순수 JSON 응답을 반환하는 데 아무런 문제가 없었습니다.

요약하면,

- 시스템 프롬프트를 준비된 레코드 데이터와 결합합니다.
- 이 결합된 프롬프트는 OpenAI의 API를 통해 GPT-3.5 모델로 전송됩니다.
- AI 응답의 창의성과 일관성의 균형을 맞추기 위해 0.3의 온도 설정을 사용합니다.
- API 호출에는 응답 크기를 제한하고 비용을 제어하기 위한 max_tokens 매개변수가 포함됩니다.

AI의 응답을 받으면 제안된 태그를 처리하고 적용하기 위해 여러 단계를 거칩니다:

* **JSON 파싱**: 응답을 JSON으로 파싱하려고 시도합니다. 파싱이 실패하면 오류를 기록하고 해당 레코드의 태깅을 건너뜁니다.
* **스키마 검증**: 파싱된 JSON을 예상 스키마("tags" 배열이 있는 객체)에 대해 검증합니다. 이는 AI 응답의 구조적 편차를 포착합니다.
* **태그 검증**: 제안된 태그를 유효한 프로젝트 태그 목록과 상호 참조합니다. 이 단계는 AI가 오해했거나 프롬프트 생성과 응답 처리 사이에 프로젝트 태그가 변경된 경우 발생할 수 있는 프로젝트에 존재하지 않는 태그를 필터링합니다.
* **중복 제거**: 중복 태깅을 피하기 위해 AI의 제안에서 중복된 태그를 제거합니다.
* **적용**: 검증되고 중복 제거된 태그가 데이터베이스의 레코드에 적용됩니다.
* **로깅 및 분석**: 최종 적용된 태그를 기록합니다. 이 데이터는 시스템 성능을 모니터링하고 시간이 지남에 따라 개선하는 데 유용합니다.

## 과제

Blue에서 AI 기반 자동 태깅을 구현하는 것은 여러 고유한 과제를 제시했으며, 각각 강력하고 효율적이며 사용자 친화적인 기능을 보장하기 위한 혁신적인 솔루션이 필요했습니다.

### 대량 작업 실행 취소

AI 태깅 기능은 개별 레코드와 대량으로 모두 수행할 수 있습니다. 대량 작업의 문제는 사용자가 결과를 마음에 들어하지 않으면 수천 개의 레코드를 수동으로 검토하고 AI의 작업을 실행 취소해야 한다는 것입니다. 분명히 이는 받아들일 수 없습니다.

이를 해결하기 위해 혁신적인 태깅 세션 시스템을 구현했습니다. 각 대량 태깅 작업에는 고유한 세션 ID가 할당되며, 해당 세션 중에 적용된 모든 태그와 연결됩니다. 이를 통해 특정 세션 ID와 연결된 모든 태그를 간단히 삭제하여 실행 취소 작업을 효율적으로 관리할 수 있습니다. 또한 관련 감사 추적도 제거하여 실행 취소된 작업이 시스템에 흔적을 남기지 않도록 합니다. 이 접근 방식은 사용자가 필요한 경우 쉽게 변경 사항을 되돌릴 수 있다는 것을 알고 AI 태깅을 실험할 수 있는 자신감을 제공합니다.

### 데이터 프라이버시

데이터 프라이버시는 저희가 직면한 또 다른 중요한 과제였습니다.

사용자들은 프로젝트 데이터를 저희에게 맡기고 있으며, 이 정보가 OpenAI에 의해 보관되거나 모델 학습에 사용되지 않도록 하는 것이 가장 중요했습니다. 저희는 여러 측면에서 이 문제를 해결했습니다.

먼저 OpenAI와 저희 데이터를 모델 학습에 사용하는 것을 명시적으로 금지하는 계약을 체결했습니다. 또한 OpenAI는 처리 후 데이터를 삭제하여 추가적인 프라이버시 보호 계층을 제공합니다.

저희 측에서는 담당자 세부 정보와 같은 민감한 정보를 AI로 전송되는 데이터에서 제외하는 예방 조치를 취했습니다. 이렇게 하면 특정 개인의 이름이 다른 데이터와 함께 제3자에게 전송되지 않습니다.

이러한 포괄적인 접근 방식을 통해 최고 수준의 데이터 프라이버시와 보안을 유지하면서 AI 기능을 활용할 수 있습니다.

### 속도 제한 및 오류 포착

저희의 주요 관심사 중 하나는 확장성과 속도 제한이었습니다. 각 레코드에 대한 직접적인 OpenAI API 호출은 비효율적이고 특히 대규모 프로젝트나 피크 사용 시간 동안 속도 제한에 빠르게 도달할 수 있었을 것입니다. 이를 해결하기 위해 요청을 배치 처리하고 자체 큐잉 시스템을 구현할 수 있는 백그라운드 서비스 아키텍처를 개발했습니다. 이 접근 방식은 API 호출 빈도를 관리하는 데 도움이 되며 대량의 레코드를 더 효율적으로 처리할 수 있게 하여 높은 부하에서도 원활한 성능을 보장합니다.

AI 상호작용의 특성상 가끔 오류나 예상치 못한 출력에 대비해야 했습니다. AI가 유효하지 않은 JSON이나 예상 형식과 일치하지 않는 출력을 생성하는 경우가 있었습니다. 이를 처리하기 위해 시스템 전체에 강력한 오류 처리 및 파싱 로직을 구현했습니다. AI 응답이 유효한 JSON이 아니거나 예상되는 "tags" 키를 포함하지 않으면, 시스템은 잠재적으로 손상된 데이터를 처리하려고 시도하는 대신 태그가 제안되지 않은 것처럼 처리하도록 설계되었습니다. 이렇게 하면 AI의 예측 불가능성에도 불구하고 시스템이 안정적이고 신뢰할 수 있게 유지됩니다.

## 향후 개발

저희는 기능과 Blue 제품 전체가 결코 "완성"되지 않는다고 믿습니다 — 항상 개선의 여지가 있습니다.

초기 구축에서 고려했지만 범위 설정 단계를 통과하지 못한 일부 기능이 있었지만, 향후 어떤 형태로든 구현할 가능성이 높으므로 주목할 가치가 있습니다.

첫 번째는 태그 설명을 추가하는 것입니다. 이를 통해 최종 사용자는 태그에 이름과 색상뿐만 아니라 선택적 설명도 제공할 수 있습니다. 이는 추가 맥락을 제공하고 잠재적으로 정확도를 향상시키기 위해 AI에도 전달됩니다.

추가 맥락이 유용할 수 있지만, 도입할 수 있는 잠재적 복잡성을 염두에 두고 있습니다. 유용한 정보를 제공하는 것과 너무 많은 세부 사항으로 사용자를 압도하는 것 사이에는 미묘한 균형이 있습니다. 이 기능을 개발하면서 추가된 맥락이 사용자 경험을 복잡하게 만들기보다는 향상시키는 최적점을 찾는 데 집중할 것입니다.

아마도 가장 흥미로운 향상 기능은 AI 자동 태깅과 [프로젝트 관리 자동화 시스템](/platform/features/automations)의 통합입니다.

즉, AI 태깅 기능이 자동화의 트리거 또는 액션이 될 수 있다는 의미입니다. 이는 다소 단순한 AI 분류 기능을 작업을 위한 AI 기반 라우팅 시스템으로 전환할 수 있으므로 엄청난 가능성을 가지고 있습니다.

다음과 같은 자동화를 상상해보세요:

AI가 레코드를 "중요"로 태그할 때 -> "관리자"에게 할당하고 맞춤 이메일 전송

즉, 레코드를 AI 태그할 때 AI가 중요한 문제라고 판단하면 자동으로 프로젝트 관리자를 할당하고 맞춤 이메일을 보낼 수 있습니다. 이는 [프로젝트 관리 자동화 시스템의 이점](/platform/features/automations)을 순수한 규칙 기반 시스템에서 진정한 유연한 AI 시스템으로 확장합니다.

프로젝트 관리에서 AI의 최전선을 지속적으로 탐구함으로써, 현재의 요구사항을 충족할 뿐만 아니라 미래의 업무를 예측하고 형성하는 도구를 사용자에게 제공하는 것을 목표로 합니다. 언제나 그렇듯이, 모든 향상 기능이 프로젝트 관리 프로세스에 실제적이고 실용적인 가치를 더하도록 사용자 커뮤니티와 긴밀히 협력하여 이러한 기능을 개발할 것입니다.

## 결론

이제 끝입니다!

이는 구현하기 재미있는 기능이었으며, 이전에 출시한 [AI 콘텐츠 요약](/insights/ai-content-summarization)과 함께 AI로의 첫 발걸음 중 하나였습니다. AI가 미래의 프로젝트 관리에서 점점 더 큰 역할을 할 것이라는 것을 알고 있으며, 고급 LLMs(대규모 언어 모델)를 활용한 더 혁신적인 기능을 출시하기를 기대하고 있습니다.

이를 구현하는 동안 고려해야 할 사항이 꽤 많았으며, 특히 Blue의 기존 [프로젝트 관리 자동화 엔진](/insights/benefits-project-management-automation)과 함께 이 기능을 향후 어떻게 활용할 수 있을지에 대해 매우 기대하고 있습니다.

또한 흥미로운 읽을거리가 되었기를 바라며, 여러분이 매일 사용하는 기능을 엔지니어링하는 방법에 대한 통찰을 제공하기를 바랍니다.
